{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import genfromtxt\n",
      "from sklearn import linear_model, decomposition\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_data(filename):\n",
      "    \"\"\" Load CSV into numpy array \"\"\"\n",
      "    return np.genfromtxt(open(filename,'rb'), delimiter=',')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = load_data('./data/train.csv')\n",
      "y = load_data('./data/trainLabels.csv')\n",
      "test = load_data('./data/test.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##How to choose the component of PCA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca = decomposition.PCA()\n",
      "pca.fit(X, y)\n",
      "plt.plot(pca.explained_variance_)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[<matplotlib.lines.Line2D at 0x10f533690>]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Semisupervised method"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "I tried the \"semisupervised\" method but it didn't work for me. This was my procedure:\n",
      "\n",
      "1. train_test_split with a test set of 30%.\n",
      "\n",
      "2. Train using the remaining 70% -> accuracy of test set = 0.913\n",
      "\n",
      "3. Predicted the results and took the records with \"good probabilities\"( > 95%) I got 53% of good probabilities.\n",
      "\n",
      "4. Created a bigger training set using the original 70% and the new 4785 examples.\n",
      "\n",
      "5. Train a new classifier\n",
      "\n",
      "Repeat from (3) 2 more times.\n",
      "\n",
      "Each time the \"good probabilities\" percentage increases; in 3 iterations I got to from 53% to 92% but the error on the original test set was very similar 92-93%. Same story in the public test set mainly the same accuracy as the SVM benchmark.\n",
      "\n",
      "I tried using and SVM(C=10) alone and with a pca with 12 components.\n",
      "\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "I got some progress but it was more playing with different SVM parameters, as I mention previously I \n",
      "found over-fitting to be a problem so increasing C helped me. The semi-supervised idea gave me a small \n",
      "boost but after reaching 95% every small improvement is important! On the other hand I believe I am \n",
      "over-fitting the public Leaderboard a little bit.\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}